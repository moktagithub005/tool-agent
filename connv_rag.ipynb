{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea8b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load\n",
    "# Filename: 01_intro_chatbot.ipynb\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load Groq API key from environment variable\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593b55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##llm model\n",
    "# Import ChatGroq from langchain_groq\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Create the chatbot model\n",
    "model = ChatGroq(\n",
    "    temperature=0.7,\n",
    "    groq_api_key=groq_api_key,\n",
    "    model=\"gemma2-9b-it\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d62e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Ajay, it's nice to meet you! \\n\\nI'm excited to learn more about Unisole.  Could you tell me a little bit about it? What does Unisole do? What inspired you to start it?  \\n\\nI'm always interested in hearing about innovative new companies and the stories behind them.  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 26, 'total_tokens': 98, 'completion_time': 0.130909091, 'prompt_time': 0.001410019, 'queue_time': 0.270275001, 'total_time': 0.13231911}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--05189100-14b6-46d8-a392-d839a41fa1e3-0', usage_metadata={'input_tokens': 26, 'output_tokens': 72, 'total_tokens': 98})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## langchian message history \n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "## simulate humam message \n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is ajay mokta. i am the founder of unisole\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be7026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ajay Mokta. ðŸ˜Š  You told me! \\n\\n\\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 44, 'total_tokens': 72, 'completion_time': 0.050909091, 'prompt_time': 0.001632699, 'queue_time': 0.273521431, 'total_time': 0.05254179}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--72e2bbe1-1b25-45ac-a5b8-ab7c31c71306-0', usage_metadata={'input_tokens': 44, 'output_tokens': 28, 'total_tokens': 72})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combining ai and human messages\\\n",
    "from langchain_core.messages import AIMessage\n",
    "## provide history to understand proper flow\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"hi, i am ajay mokta.\"),\n",
    "    AIMessage(content=\"hello Ajay, how can i help you today\"),\n",
    "    HumanMessage(content=\"hey, what is my name?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4c4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b44fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## store message history\n",
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e5f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe6538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history  # <- âœ… notice: no parentheses\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea71ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define confi session\n",
    "\n",
    "config={\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"chat_2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915463b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you said your name is Ajay Mokta!  \n",
      "\n",
      "Is there something specific you want to know or do with that information? ðŸ˜Š  I'm happy to help!  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"my name is ajay mokta?\")],\n",
    "    config=config\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de3b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You told me your name is Ajay Mokta!  \n",
      "\n",
      "Do you need me to remember that for later?  Perhaps you'd like to tell me something else about yourself?  ðŸ˜„ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my  name?\")],\n",
    "    config=config\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32332c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2dd51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"input_history\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d90266",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4275105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Please tell me your name so I can say it! ðŸ˜Š  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 31, 'total_tokens': 48, 'completion_time': 0.030909091, 'prompt_time': 0.00148221, 'queue_time': 0.263029801, 'total_time': 0.032391301}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--688b0d92-f02e-4d42-a3d7-b34b40c50e1d-0', usage_metadata={'input_tokens': 31, 'output_tokens': 17, 'total_tokens': 48})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke([\n",
    "    HumanMessage(content=\"Hi, Say my name\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c698f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_chat2 = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_2\" # Or whatever session ID you introduced yourself in\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e8bf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am Ajay Mokta, founder of Unisole.\")],\n",
    "    config=config_chat2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca978c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI (1st turn): Hello Ajay Mokta, founder of Unisole! It's great to meet you. \n",
      "\n",
      "What can I do for you today? Are you looking for information about Unisole, or do you have a specific question for me? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"AI (1st turn): {response1.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c47cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config_chat2 # using the SAME session_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa7c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI (2nd turn): You said your name is Ajay Mokta.  ðŸ˜Š  \n",
      "\n",
      "Is there anything else I can help you with?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"AI (2nd turn): {response2.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "870e4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history  # previously defined function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f636d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"), \n",
    "    MessagesPlaceholder(variable_name=\"input_history\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a756eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dce2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤…à¤œà¤¯ à¤®à¥‹à¤•à¥à¤¤à¤¾ à¤œà¥€ ! à¤¹à¤¿à¤®à¤¾à¤šà¤² à¤¸à¥‡ à¤†à¤ªà¤•à¤¾ à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆ! \n",
      "\n",
      "à¤®à¥à¤à¥‡ à¤¬à¤¤à¤¾à¤‡à¤, à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤? ðŸ˜Š\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \n",
    "        \"input_history\": [HumanMessage(content=\"Hi Ajay Mokta from Himachal\")],\n",
    "        \"language\": \"Hindi\"\n",
    "    }\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec1326dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat4\"\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
